\documentclass[12pt,letterpaper]{article}

\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}	% Including figure files
\usepackage{mathtools}  %loads amsmath as well
\usepackage{amssymb}	% Extra maths symbols
\usepackage[english]{babel}
\usepackage{float}
\usepackage{bm}
\usepackage{indentfirst}
\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{pgfplots}
\usepackage{color,soul}
%\pgfplotsset{compat=1.12}
\definecolor{mygray}{RGB}{125,125,125}
\definecolor{myred}{RGB}{255,60,60}
\definecolor{myblue}{RGB}{60,60,255}
\renewcommand{\arraystretch}{1.2}

% potential journals:
    % journal of computational physics
    % computers and fluids
    % international journal for numerical methods in fluids
    % aiaa
    % journal of fluid mechanics

\title{A Multiresolution Scheme Featuring Fully Adaptive Blocks for Simulating Reactive Flows}

\author{
  Brandon Gusto\\
  Department of Scientific Computing\\
  Florida State University\\
  Tallahassee, FL 32306 \\
  \texttt{bgusto@fsu.edu} \\
  %% examples of more authors
  \And
  Tomasz Plewa \\
  Department of Scientific Computing\\
  Florida State University\\
  Tallahassee, FL 32306 \\
  \texttt{tplewa@fsu.edu} \\
}

\begin{document}
\maketitle

\begin{abstract}
    We present a generalization of Harten's original multiresolution scheme for
    simulating reactive flows on logically rectangular block-structured adaptive
    mesh refinement (AMR) grids in one and two dimensions. The scheme addresses
    a major shortcoming of tree-based AMR codes, which is the creation of blocks
    with a low filling factor; that is, many cells in such a block are resolved
    beyond the desired error tolerance, necessitating excessive computational
    resources.  To overcome this issue, we introduce a multiresolution
    representation of the solution, not only to adapt the grid but also to
    adaptively compute fluxes and sources on each block. The scheme recycles
    regularity information obtained by the multiresolution grid adaptation in
    order to select flux and source calculations which may be accurately
    replaced by interpolation from the multiresolution basis. A block which
    employs this scheme is denoted as a fully adaptive block (FAB).  The error
    introduced by this approximation is shown to be of the same order as the
    local truncation error of the reconstruction scheme. Thus the rate of
    convergence of the underlying spatial reconstruction scheme is preserved.
    Additionally with respect to parallel applications, the multiresolution
    transform and computation of fluxes and sources on FABs is asynchronous,
    requiring only one synchronization step which is equivalent to the filling
    of ghost cells for each block. The efficiency of the scheme is demonstrated
    using several one and two-dimensional problems.
\end{abstract}

% keywords can be removed
\keywords{Multiresolution \and Adaptive Mesh Refinement \and Conservation Laws}

\section{Introduction}

    % paragraph introduces the need for spatially adaptive grids
    Fluid flows are often characterized by disparate spatial and temporal length
    scales. Certain features such as turbulence or shocks necessitate
    significantly higher resolution than smooth regions of the flow.  In
    reacting flows, combustion fronts often act in highly localized regions, and
    on very small time scales. Naturally, intense effort has gone into the
    development of methods which employ a multi-scale or adaptive strategy to
    accurately simulate such flows without over-resolving smooth areas of the
    domain.

    % paragraph introducing adaptive mesh refinement as a concept
    The most popular strategy to accurately capture regions of interest in fluid
    simulations is to introduce a non-uniform spatial grid, with higher
    resolution in regions of interest.  Methods which introduce a hierarchy of
    nested grid resolutions are generally described as adaptive mesh refinement
    (AMR) methods. AMR methods rely on estimates of the local truncation error (LTE)
    of the numerical scheme to determine regions where refinement is necessary for solution
    accuracy. Several strategies to approximate the LTE are used (\hl{list
    methods}).
    %\cite{Berger1984}.  Alternative methods include
    %feature-based refinement, and evaluation of gradient information (references
    %here).

    % talk about block-structured AMR
    Regarding the implementation of AMR methods on large parallel computers,
    certain engineering realities have neccessitated the reduction in
    granularity of the adaptive refinement. To use a single computational cell
    as the unit for refinement (i.e. cell-based refinement) introduces a number
    of costly compromises. Firstly, such an adapted grid requires the
    reconstruction method of choice to utilize nonuniform stencils, requiring
    increased computational resources. More significantly, the cell-based
    refinement requires extremely costly data traversal. Traversing tree space
    requires an average $\mathcal{O}(n^d)$ (\hl{confirm this?}) operations. Thus
    most AMR codes make use of some type of block-based approach. Tree-based
    block-structured codes, where each block consists of a fixed number of
    cells, are a very popular choice. These types of approaches are implemented
    in a number of AMR libraries including Paramesh (\hl{cite}), p4est
    (\hl{cite}, and others. This approach allows for simple mesh management
    procedures, and scales well for very large number of processors in parallel.

    % paragraph reviews the work of harten and multiresolution methods
    Alternate approaches to dynamic grid adaptation based on wavelet theory have
    become popular in recent years. The first such effort was introduced in a
    seminal paper by Harten \cite{harten1994}, where a multiresolution
    representation of the discrete solution on a uniform grid was used for
    adaptively computing the divergence of the flux within a finite volume
    framework. Rather than adapt the grid by truncating the wavelet basis, the
    idea was to accelerate the computation of high-order essentially
    non-oscillatory (ENO) schemes using the multiresolution information. Fluxes
    in smooth regions were interpolated from fluxes obtained at interfaces
    corresponding to coarser grid levels. The original scheme was applied solely
    to hyperbolic conservation laws, but was then expanded by Bihari et. al. to
    two-dimensional simulations in (\hl{citation}), followed by the inclusion of
    viscous terms in (\hl{citation}), and then tp source terms in the context of
    reactive flows in (\hl{citation}). These works retained the original flavor
    of Harten's scheme, which was to represent the discrete solution on a
    uniform grid, but uses a multiresolution representation of the solution to
    identify regions where flux (and source term) computations may be avoided.
    The multiresolution transform is obtained by using average-interpolating
    wavelets as basis functions.

    % review the multiresolution-adaptive papers
    Although Harten's original scheme was intended to be an alternative to
    spatially non-uniform grid adaptation, a series of papers have since
    reintroduced this concept of non-uniform grids within the MR framework. Thus
    the AMR approach has been redeveloped but with the refinement criterion
    defined by the MR representation rather than with the traditional metrics
    mentioned previously. The first fully adaptive scheme was presented by Cohen
    et. al. to study hyperbolic conservation laws in two dimensions in
    (\hl{cite}).

\section{Governing Equations and Finite Volume Discretization}

    % describe merging block-structured AMR with Harten's scheme
    In the present work we are interested in numerically solving conservation
    laws of the form
    \begin{equation}
    \begin{cases}
      u_{t} + f(u)_{x} = s(u) \\    
      u(x,0) = u_{0}(x),
    \end{cases}
    \label{claw}
    \end{equation} where $u$ represents a conserved quantity, $f(u)$ is the flux
    function, and $s(u)$ is a source term. For the sake of presentation, we let
    the scalar equation (\ref{claw}) stand in for the more complicated systems
    of conversation laws which will be the focus of our applications.  In the
    finite volume formulation, the solution $u(x,t)$ is approximated by volume
    averages defined within each cell $I_{i} = \left[ x_{i}-\frac{h}{2},
    x_{i}+\frac{h}{2} \right]$ in the computational domain.  The cell width $h$
    is determined by the number of cells, $N$, and the size of the domain
    $\Omega \in \left[a,b\right]$.  The cell averages are given by
    \begin{equation}
        u_{i}(t) = \frac{1}{h} \int_{x_{i-1/2}}^{x_{i+1/2}} u(\xi,t) d \xi,
    \end{equation}
    where for convenience we use $i \pm 1/2$ in the subscripts to
    indicate the left and right interfaces of the target cell (i.e.
    $x_{i+1/2} =
    x_{i} + \frac{h}{2}$). The governing equations are cast into the
    semi-discrete conservative form,
    \begin{equation}
        \frac{du_{i}(t)}{dt} = -\frac{1}{h} \left( \hat{f}_{i+1/2} -
        \hat{f}_{i-1/2} \right),
        \label{ode}
    \end{equation}
    where the numerical flux is evaluated as
    \begin{equation}
        \hat{f}_{i + 1/2} = \hat{f}(u^{-}_{i+1/2}, u^{+}_{i+1/2}).
    \end{equation}
    In the present work, the reconstruction method of choice is a fifth-order
    weighted essentially non-oscillatory (WENO) scheme.

    \subsection{WENO}

    \subsection{Time Integration}

        % define evolution operator as in domingues2008
        Once the system of ordinary differential equations (\ref{ode}) is
        established, the objective is to integrate them forward in time. In our
        implementation we use a second-order explicit Runge-Kutta scheme to
        advance. This is summarized by
        \begin{equation}
            \bm{u}^{n+1} = \bm{E} \bm{u}^{n},
        \end{equation}
        where $\bm{E}$ represents the nonlinear evolution operator, and codifies the
        temporal and spatial discretizations.

\section{Harten's Multiresolution Scheme on a Uniform Grid}

    % describe overview of transform, and average-interpolating wavelets
    We present here a review of Harten's multiresolution method for adaptive
    flux computations within the original context of uniform, one-dimensional
    grids. This is necessary to illustrate the extension of the scheme to
    block-structured AMR grids. The multiresolution approach is based on a
    hierarchy of nested discretizations on the domain of interest, $\Omega$.
    The hierarchy of grids consists level $l=1$ and is
    refined repeatedly by a factor of two until some
    predetermined maximum level $l=L$.  The grids are defined by
    \begin{equation}
        \bm{\mathcal{G}}_{l} = \left\{ x_{i}^{l} \right\}_{i=0}^{N_{l}}, \text{ }
        \text{ } \text{ } \text{ } x_{i}^{l} = i \cdot h_{l}, \text{ }
        \text{ } h_{l} = 2^{L-l} \cdot h_{L}, \text{ } \text{ } N_{l} = N_{L}
        / 2^{L-l},
    \end{equation}
    where $h_{l}$ and $N_{l}$ denote the cell width and number of cells,
    respectively, on level $l$. We denote the finest grid by
    $\bm{\mathcal{G}}_{L}$. denote the index space of cells on each level
    of the hierarchy by $\bm{\mathcal{I}}^{l} = (1,\dots,N^{l})$.

    \subsection*{Encoding}

        % describe the prediction operator, and detail coefficients
        Given a vector of discrete cell averages at the finest resolution,
        $\bm{u}^{L}$, the multiresolution representation is obtained by the
        following operations:
        \begin{enumerate}
            \item[] \textit{Split:} The cells at grid level $l$ are split into two
                sets, even and odd.
            \item[] \textit{Project:} The cells at level $l$ are projected, or
                coarsened by means of volume averaging onto the coarser grid level
                $l-1$.
            \item[] \textit{Predict}: A stencil of odd cell averages at level $l$ are predicted
                    by an average-interpolating polynomial based on cells at level
                    $l-1$.
        \end{enumerate}
        The splitting of cells is done according to the cell index. The projection
        is defined by a linear operator $\bm{P}_{l+1}^{l}$, which performs the
        mapping $\bm{P}_{l+1}^{l} : \bm{u}^{l+1} \mapsto \bm{u}^{l}$. The
        projection preserves averages at the finer level, by design, and in the
        context of a uniform grid is the simple averaging of parent cells,
        \begin{equation}
            u^{l}_{i} = \frac{1}{2} ( u^{l+1}_{2i} + u^{l+1}_{2i+1} ), \text{ } \text{ } \text{ } \text{ } \forall i \in \mathcal{I}^{l}
        \end{equation}
        The prediction operator likewise performs the mapping
        $\bm{P}_{l}^{l+1} : \bm{u}^{l} \mapsto \bm{u}^{l+1}$. This is done
        using a unique average-interpolating polynomial of degree $2s$ to
        predict, based on a stencil of cell-averages at grid level $l$, the odd
        cell averages at the finer level level $l+1$. The prediction is given
        by the centered interpolant,
        \begin{equation}
            \tilde{u}_{2i+1}^{l+1} = u_{i}^{l} - \sum_{p=1}^{s}
            \gamma_{p} \left( u^{l}_{i-p} - u^{l}_{i+p} \right), \text{ } \text{ } \text{ } \text{ } \forall i \in \mathcal{I}^{l},
        \end{equation}
        where the coefficients $\gamma_{i}$ are supplied in Table
        (\ref{coeff1}). The order of accuracy of each interpolant is $r=2s+1$.
        \begin{table}[]
            \center
            \begin{tabular}{|l|l|l|l|l|}
            \hline
                order    & $\gamma_{1}$ & $\gamma_{2}$ & $\gamma_{3}$ & $\gamma_{4}$ \\ \hline
                3 & 1/8          & 0            & 0            & 0            \\ \hline
                5 & -22/128      & 3/128        & 0            & 0            \\ \hline
                7 & 0            & 0            & 0            & 0            \\ \hline
                9 & 0            & 0            & 0            & 0            \\ \hline
            \end{tabular}
            \label{coeff1}
            \caption{For the derivation of these coefficients, the reader is referred to Appendix (\hl{ref}).}
        \end{table}

        \begin{table}[]
            \center
            \begin{tabular}{|l|l|l|l|l|}
            \hline
                order    & $\beta_{1}$ & $\beta_{2}$ & $\beta_{3}$ & $\beta_{4}$ \\ \hline
                1 & 1/2          & 0            & 0            & 0            \\ \hline
                3 & 9/16         & -1/16        & 0            & 0            \\ \hline
                5 & 0            & 0            & 0            & 0            \\ \hline
                7 & 0            & 0            & 0            & 0            \\ \hline
            \end{tabular}
            \label{coeff1}
            \caption{}
        \end{table}
        Once the prediction is made, the difference information on level $l$ is
        obtained by computing the detail coefficient as
        \begin{equation}
            d^{l}_{i} = u^{l+1}_{2i+1} - \tilde{u}^{l+1}_{2i+1}, \text{ } \text{ } \text{ } \text{ } \forall i \in \mathcal{I}^{l}.
        \end{equation}
        for each cell.  The encoding procedure is complete when the detail
        coefficients have been computed on all levels $l=0,\dots,L-1$.  The
        entire procedure can be succinctly written in terms of a matrix-vector
        operation to yield the multiresolution representation of the data,
        $u_{M}^{L}$, as
        \begin{equation}
            \bm{u}^{L}_{M} = \bm{M} \bm{u}^{L} = \left( \bm{d}^{L-1}, \bm{d}^{L-2},
            \dots, \bm{d}^{0}, \bm{u}^{0} \right)^{T}.
        \end{equation}
        Here the multiresolution operator $\bm{M}$ contains the prediction
        operation and subsequent detail coefficient calculation for each cell
        on each level of the hierarchy.

    \subsection*{Truncation}

        % describe truncation proceudure
        Once the difference information has been computed, compression of the
        fine-grid cell averages $\bm{u}^{L}$ is obtained by truncating
        coefficients whose magnitude is below a prescribed level-dependent
        threshold, $\varepsilon_{l}$.  In \cite{harten1994} the following
        threshold is proposed
        \begin{equation}
            \varepsilon_{l} = \varepsilon / 2^{L-l}.
        \end{equation}
        The detail coefficients are truncated according to
        \begin{equation}
            \tilde{d}^{l}_{i} =
                \begin{cases}
                    d^{l}_{i}, \text{ } \text{if} \text{ } |d^{l}_{i}| > \varepsilon_{l} \\
                    0, \text{ } \text{if} \text{ } |d^{l}_{i}| \leq \varepsilon_{l}.
                \end{cases}
        \end{equation}

    \subsection*{Decoding}

        % describe decoding
        The fine-grid solution is reconstructed by computing from levels
        $l=0,\dots,L-1$ the following
        \begin{align}
            u_{2i+1}^{l+1} & = d_{i}^{l} + u_{i}^{l} - \sum_{p=1}^{s}
            \gamma_{p} \left( u^{l}_{i-p} - u^{l}_{i+p} \right) \\
            u_{2i}^{l+1} & = 2 u_{i}^{l} - u_{2i+1}^{l+1},
        \end{align}
        for each cell on the level.
        \begin{equation}
            \bm{u}^{L}_{M} = \bm{M} \bm{u}^{L} = \left( \bm{d}^{L-1}, \bm{d}^{L-2},
            \dots, \bm{d}^{0}, \bm{u}^{0} \right)^{T}.
        \end{equation}

    \subsection*{Adaptive Calculation of Fluxes and Sources}

        % dicuss computation of fluxes and sources
        That is, we define a mask $\mathcal{M}(\varepsilon)$.
        Once the detail coefficients have been obtained, the MR scheme
        proceeds by setting a threshold $\varepsilon$ and truncating coefficients
        which have an absolute value below the threshold. Lastly, the inverse
        transform then starts from grid $l=L$ and at each interface either
        computes fluxes using the fine-grid scheme, or interpolates them using
        the MR basis. The fluxes are interpolated by
        \begin{align}
            & \tilde{f}_{2i+1}^{l-1} \approx \sum_{p=1}^{s+1} \beta_{p} \left(
            \hat{f}^{l}_{i-p+1} + \hat{f}^{l}_{i+p} \right) \\
            & s=0, \text{ } \beta_{1} = 1/2 \\
            & s=1, \text{ } \beta_{1} = 9/16, \text{ } \beta_{2} = -1/16
        \end{align}
        where the interpolants are of degree $2s+1$. The coefficients for
        various degrees of polynomial interpolants are shown in Table (ref).
        The process repeats until all fluxes are either computed or
        interpolated on the fine grid $l=0$.

    \subsection*{Error Analysis}

\section{Asynchronous Fully Adaptive Block Scheme}

    % two main issues: no jump greater than one refinement level, and no
    % incomplete trees

    % illustration of parallel encoding
    \begin{figure}[H]
        \center
        \input{parallel_fwt.tex}
        \caption{A block of consisting of $N^{0} = 16$ cells is shown. Four
        ghost cells are included on each end of the block, allowing the
        multiresolution decomposition to descend two levels (to grid level
        $l=2$). Interpolation stencils for the computation of detail
        coefficients at levels $l=1, l=2$ are shown, indicating the need for ghost cells.}
    \end{figure}
    % illustration amr block tree structure
    \begin{figure}[H]
        \center
        \input{amr_tree.tex}
        \caption{}
    \end{figure}

    % pseudocode of algorithm

    % illustration of parallel issue
    \begin{figure}[H]
        \center
        \input{parallel_flux.tex}
       \caption{Two examples of flux interpolation on a hierarchy of grids
        on Process 1: one procedure requires flux data from the adjacent
        process, the other does not.}
    \end{figure}

    \subsection*{Buffer Region}

    \subsection*{Load Balancing}

\section{Numerical Results}

    \subsection*{Convergence Analysis for Smooth Advection Problem}

        \begin{center}\vspace{1cm}
        \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
        \hline
                   & \multicolumn{4}{l|}{$\varepsilon = 0.0$}              & \multicolumn{4}{l|}{$\varepsilon = 10^{-12}$}         \\ \hline
        grid cells & $L_{1}$ error & order & $L_{\infty}$ error & order & $L_{1}$ error & order & $L_{\infty}$ error & order \\ \hline
        16         &               &       &                    &       &               &       &                    &       \\ \hline
        32         &               &       &                    &       &               &       &                    &       \\ \hline
        64         &               &       &                    &       &               &       &                    &       \\ \hline
        128        &               &       &                    &       &               &       &                    &       \\ \hline
        256        &               &       &                    &       &               &       &                    &       \\ \hline
                   & \multicolumn{4}{l|}{$\varepsilon = 10^{-6}$}          & \multicolumn{4}{l|}{$\varepsilon = 10^{-4}$}          \\ \hline
        grid cells & $L_{1}$ error & order & $L_{\infty}$ error & order & $L_{1}$ error & order & $L_{\infty}$ error & order \\ \hline
        16         &               &       &                    &       &               &       &                    &       \\ \hline
        32         &               &       &                    &       &               &       &                    &       \\ \hline
        64         &               &       &                    &       &               &       &                    &       \\ \hline
        128        &               &       &                    &       &               &       &                    &       \\ \hline
        256        &               &       &                    &       &               &       &                    &       \\ \hline
        \end{tabular}
        \end{center}\vspace{1cm}

    \subsection*{Two Blast Waves}

    \subsection*{Nuclear Burning}

    \subsection*{Mach Reflection}
    Using the inviscid flow assumption, the dynamics of compressible fluids are
    modeled using the reactive Euler equations \hl{add domain notation}
    \begin{equation}
       u_{t} + f(u)_{x}
       + g(u)_{y} = s(u),
        \label{goveq}
    \end{equation}
    where $u = \left( \rho, \rho u, \rho v, \rho w, E \right)^{T}$ is
    the state vector, the flux vectors are given by
    \begin{equation}
        f = 
    \begin{pmatrix}
    \rho u \\ \rho u^2 + p \\ \rho u v \\ u( E + p )
    \end{pmatrix}, \text{ } \text{ } \text{ }
        g = 
    \begin{pmatrix}
    \rho v \\ \rho u v \\ \rho v^2 + p \\ v( E + p )
    \end{pmatrix},
    \end{equation}
    and $s(u)$ represents sources. The total energy per
    unit volume is given by
    \begin{equation*}
        E = \rho \left( \frac{1}{2} \mathbf{V}^{2} + e \right),
    \end{equation*}
    where $e$ is the internal energy and the kinetic energy contribution is
    \begin{equation*}
        \frac{1}{2} \mathbf{V}^{2} = \frac{1}{2} \mathbf{V}
        \cdot \mathbf{V} = \frac{1}{2} \left( u^2 + v^2 \right).
    \end{equation*}
    The system of nonlinear equations is closed by an
    equation of state which is in general not derived from that of an ideal gas.

\section{Acknowledgements}

\appendix

\section{Multiresolution Analysis}

    % describe multiresolution analysis (sourced from tymczak2000)
    A multiresolution analysis (MRA) of the Lebesgue space
    $L^{2}(\mathbb{R})$ defines a sequence of nested approximation spaces.
    These spaces satisfy certain self-similarity properties in both space
    and scale. An MRA defines a sequence of closed subspaces $\{ \mathcal{V}_{j} : j \in
    \mathbb{Z} \}$ such that
    \begin{equation*}
        \mathcal{V}_{0} \subset \mathcal{V}_{1} \subset \mathcal{V}_{2} \subset \cdots
        \subset L^{2}.
    \end{equation*}
    The complement of $\mathcal{V}_{j} \in \mathcal{V}_{j+1}$ is defined by
    $\mathcal{W}_{j}$, known as the detail space. This relation is defined
    by a direct summation as
    \begin{equation*}
        \mathcal{V}_{j+1} = \mathcal{W}_{j} \oplus \mathcal{V}_{j}.
    \end{equation*}
    Considering successively finer approximation spaces yields for any
    arbitrary level $J$,
    \begin{equation*}
        \mathcal{V}_{J} = \mathcal{V}_0 \oplus \mathcal{W}_0 \oplus \mathcal{W}_1 \oplus \dots \oplus \mathcal{W}_{J-1}.
    \end{equation*}
    Thus fine-scale information on any arbitrary level $J$ is represented by
    the coarsest scale plus a series of differences at higher levels.
    Interested readers can refer to (\hl{cite}) for more details on the
    construction of the bi-orthogonal multiresolution analysis used.

    %, a real-valued scaling function
    %$\phi_{j}(x) \in V_{j}$ is defined which forms a basis,
    %\begin{equation*}
    %    V_{j} = \text{span} \left\{ \phi_{j}(x+k) : \forall k \right\}.
    %\end{equation*}

\section{Derivation of Prediction Operator in One-Dimension}

    % derivation of prediction operator
    We are interested in obtaining the difference between approximation spaces at varying levels of resolution. We 
    are given cell-averaged values as input data to our wavelet transform. This data is fed to the scheme at some arbitrary maximum
    resolution level $J$, and the wavelet transform produces details coefficients at each lower level until the coarsest level,
    $j=0$, is reached. The coefficients in this case are interchangeable with the cell-averages and are denoted by $c^{j}_{k}$,
    where the level of resolution is denoted by $j$, and the spatial index is denoted by $k$. We consider an interpolating
    polynomial $p(x)$ such that 
    \begin{align}
        c^{j}_{k-1} &= \int_{x^{j}_{k-1}}^{x^{j}_{k}} p(x) dx \\
        c^{j}_{k} &= \int_{x^{j}_{k}}^{x^{j}_{k+1}} p(x) dx \\
        c^{j}_{k+1} &= \int_{x^{j}_{k+1}}^{x^{j}_{k+2}} p(x) dx.
    \end{align}
    The polynomial $p(x)$ should then predict the finer cell-averages of cell $c^{j}_{k}$ as
    \begin{align}
        \hat{c}^{j+1}_{2k} &= 2 \int_{x^{j}_{k}}^{x^{j}_{k+1/2}} p(x) dx \\
        \hat{c}^{j+1}_{2k+1} &= 2 \int_{x^{j}_{k+1/2}}^{x^{j}_{k+1}} p(x) dx
    \end{align}
    At present, it may not be clear how to implement such a scheme on a computer. However this interpolation procedure
    can be cast in a more suitable form by introducing another polynomial, the integral of $p(x)$:
    \begin{equation}
        P(x) = \int_{0}^{x} p(y) dy.
    \end{equation}
    Now the problem is to interpolate the following data
    \begin{align}
        0 &= P(x^{j}_{k-1}) \\
        c^{j}_{k-1} &= P(x^{j}_{k}) \\
        c^{j}_{k-1} + c^{j}_{k} &= P(x^{j}_{k+1}) \\
        c^{j}_{k-1} + c^{j}_{k} + c^{j}_{k+1} &= P(x^{j}_{k+2}).
    \end{align}
    This can easily be done using Lagrange polynomials. Then the predictions are given in terms of $P(x)$ by
    \begin{align}
        \hat{c}^{j+1}_{2k} &= 2 \left( P(x^{j}_{k+1/2}) - P(x^{j}_{k}) \right) \\
        \hat{c}^{j+1}_{2k+1} &= 2 \left( P(x^{j}_{k+1}) - P(x^{j}_{k+1/2}) \right).
    \end{align}
    This interpolating polynomial is cast in the Lagrange form,
    \begin{equation}
    P(x) = \sum_{i=0}^{n} y_{i} l_{i}(x),
    \end{equation}
    where $y_{i}$ are the functional data, and $l_{i}(x)$ are the Lagrange polynomials. For $n=3$ these
    are given by
    \begin{align}
        l_{0}(x) &= \frac{x-x_1}{x_0-x_1} \frac{x-x_2}{x_0-x_2} \frac{x-x_3}{x_0-x_3} \\
        l_{1}(x) &= \frac{x-x_0}{x_1-x_0} \frac{x-x_2}{x_1-x_2} \frac{x-x_3}{x_1-x_3} \\
        l_{2}(x) &= \frac{x-x_0}{x_2-x_0} \frac{x-x_1}{x_2-x_1} \frac{x-x_3}{x_2-x_3} \\
        l_{3}(x) &= \frac{x-x_0}{x_3-x_0} \frac{x-x_1}{x_3-x_1} \frac{x-x_2}{x_3-x_2},
    \end{align}
    and the final interpolating polynomial is
    \begin{equation}
        P(x) = (0) l_{0}(x) + ( c^{j}_{k-1} ) l_{1}(x) + ( c^{j}_{k-1} + c^{j}_{k} ) l_{2}(x)
            + ( c^{j}_{k-1} + c^{j}_{k} + c^{j}_{k+1} ) l_{3}(x).
    \end{equation}
    Several evaluations are necessary in order to obtain the predictions. Using intervals of equal length, these values are
    \begin{align}
        P(x^{j}_{k}) &= c^{j}_{k-1} \\
        P(x^{j}_{k+1/2}) &= \frac{17}{16} c^{j}_{k-1} + \frac{1}{2} c^{j}_{k} - \frac{1}{16} c^{j}_{k+1} \\
        P(x^{j}_{k+1}) &= c^{j}_{k-1} + c^{j}_{k}.
    \end{align}
    Then the predictions of the cell-averages at the higher level of resolution are finally given by
    \begin{align}
        \hat{c}^{j+1}_{2k} & = c^{j}_{k} + \frac{1}{8} \left( c^{j}_{k-1} - c^{j}_{k+1} \right) \\
        \hat{c}^{j+1}_{2k+1} & = c^{j}_{k} - \frac{1}{8} \left( c^{j}_{k-1} - c^{j}_{k+1} \right).
    \end{align}
    This procedure could easily be extended to non-uniformly
    spaced intervals, giving different weights. Note that only the
    odd indices are counted because in the multiresolution scheme the
    data is initially split into even
    and odd signals. All data at level $j$ are just considered to
    be a copy of the even-index data at level $j+1$, whereas
    the odd-indexed data at level $j+1$ is what is predicted
    by even-indexed data at level $j+1$. Also important are the
    interpolants at the ends of the domain. Given below are the
    left and right predictions, respectively:
    \begin{align}
        \hat{c}^{j+1}_{2k+1} & = \frac{5}{8} c^{j}_{k}
        + \frac{1}{2} c^{j}_{k+1} - \frac{1}{8} c^{j}_{k+2} \\
        \hat{c}^{j+1}_{2k+1} & = \frac{1}{8} c^{j}_{k-2}
        - \frac{1}{2} c^{j}_{k-1} + \frac{11}{8} c^{j}_{k}.
    \end{align}

\bibliographystyle{unsrt}  
\bibliography{references}

\end{document}
